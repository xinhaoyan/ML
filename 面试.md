# 面试
## 回归模型和分类模型常用损失函数有哪些？各有什么优缺点
回归模型常用的损失函数有：

0-1损失函数： 

$$ L(f(x),y) = \begin{cases} 1, & y \neq f(x) \ 0, & y = f(x) \end{cases} $$

绝对损失函数：异常点多的情况下鲁棒性好；但不方便求导

$$ L(f(x), y) = |f(x)-y| $$

平方损失函数：求导方便，能够用梯度下降法优化；对异常值敏感 

$$ L(f(x),y) = (f(x)-y)^2 $$

对数损失函数/对数似然损失函数： 

$$ L(P(Y|X),Y) = -{\rm log} P(Y|X) $$

Huber 损失函数：结合了绝对损失函数和平方损失函数的优点；缺点是需要调整超参数 

$$ L_{Huber}(f, y) = \begin{cases} (f-y)^2 & |f-y| \leq \delta \ 2 \delta |f-y| - \delta^2 & |f-y| > \delta \end{cases} $$

Log-Cosh 损失函数：具有Huber的所有优点，同时二阶处处可微（牛顿法要求二阶可微） 

$$ L(f,y) = \log \cosh(f-y) $$

## 1-4 什么是结构误差和经验误差？训练模型的时候如何判断已经达到最优？
经验风险（经验损失）：模型关于训练数据集的平均损失

$$ R_{\rm emp}(f) = \frac{1}{N} \sum_{i=1}^N L(y_i,f(x_i)) 

$$ 结构风险：是在经验风险上加上表示模型复杂度的正则化项 

$$ R_{\rm srm}(f) = \frac{1}{N} \sum_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f) 

$$ 经验风险最小化的策略认为，经验风险最小的模型是最优的模型。

结构风险最小化是为了防止过拟合而提出的，结构风险最小化等价于正则化。结构风险最小化的策略认为结构风险最小的模型是最优的模型。
